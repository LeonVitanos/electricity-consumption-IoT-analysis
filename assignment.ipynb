{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical: Data Analysis\n",
    "\n",
    "In this assignment you will experiment with\n",
    "\n",
    "- exploring the data collected at a home and a weather station around the Eindhoven area,\n",
    "- building a predictive model for estimating the amount of electricity produced by the solar panels at the home given a weather forecast.\n",
    "\n",
    "This notebook will guide you through the typical steps that such work would involve. It demonstrates how to explore and clean the data, and how to use it to train predictive models.\n",
    "\n",
    "#### Goal\n",
    "\n",
    "Your task is to train a model on the time series data containing:\n",
    "\n",
    "- measurements of the amount of electricity produced by the solar panels on the roof of a home in the Eindhoven area\n",
    "- weather measurements around the Eindhoven airport\n",
    "\n",
    "in order to predict the hourly solar panel output given the weather forecast for a particular hour of a particular day.\n",
    "\n",
    "#### Jupyter notebooks\n",
    "\n",
    "For those who are new to jupyter notebooks, a typical notebook contains text cells (like this one) interleaved with code cells (the gray boxes). You can execute a cell by selecting it and pressing Shift+Enter. The expression in the last line in a cell is the output of that cell. Try executing the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "add(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find out more about jupyter notbooks at:\n",
    "\n",
    "- https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/\n",
    "- http://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Notebook%20Basics.ipynb\n",
    "- http://nbviewer.jupyter.org/github/jupyter/notebook/tree/master/docs/source/examples/Notebook/\n",
    "\n",
    "#### References\n",
    "\n",
    "The \"Python Data Scinence Handbook\" provides a good overview of using python for data data analysis and you are encouraged to consult it during this assignment:\n",
    "\n",
    "- https://jakevdp.github.io/PythonDataScienceHandbook/\n",
    "\n",
    "The \"Introduction to Statistical Learning\" [ISLR] (7th edition) book provides a good introduction to machine learning from the statistical perspective:\n",
    "\n",
    "- http://faculty.marshall.usc.edu/gareth-james/ISL/\n",
    "\n",
    "The \"Dataset Shift in Machine Learning\" book by Joaquin QuiÃ±onero-Candela, Masashi Sugiyama, Anton Schwaighofer and Neil D. Lawrence provides a good overview of the problems that may arise when the test and training inputs and outputs have different distributions. You can find more information about the book at:\n",
    "\n",
    "- https://mitpress.mit.edu/books/dataset-shift-machine-learning\n",
    "\n",
    "#### Deliverable\n",
    "\n",
    "Throughout this notebook you will find cells starting with `#TODO` and `#BEGIN_TODO`. Fill in all these TODO cells. The `#TODO` cells are meant to guide you, while the `#BEGIN_TODO` _answer cells_ will be graded.\n",
    "\n",
    "- Answer cells start and end with tags, `# // BEGIN_TODO [Q0]` and `# // END_TODO [Q0]`, for example. Do not edit these tags in any way, else your answers may not be parsed by our grading system. \n",
    "- Your answers should be provided in Python code format between the tag lines, for example:\n",
    "```\n",
    "# // BEGIN_TODO [Q0]\n",
    "q0 = 1\n",
    "# // END_TODO [Q0]\n",
    "```\n",
    "- Do not place any other code between the tags, unless explicitly requested.\n",
    "- Do not reuse the variable names from the answer cells that you are supposed to use to fill in answers, so in case of the example above, do not reuse `q0` later in the notebook.\n",
    "\n",
    "You are encouraged to play with the data and extend this notebook in order to obtain your answers. You may insert cells at any point in the notebook, as long as the question cells remain unaltered. At the end, deliver the filled in `.ipynb` file.\n",
    "\n",
    "> **IMPORTANT:** Before delivering your notebook, make sure that the cells in your notebook can be executed in sequence without errors, by executing \"Restart & Run All\" from the \"Kernel\" menu. This is also how your notebook will be evaluated.\n",
    "\n",
    "Let's get started by filling in your details in the following answer cell. Assign your names and student ids to variables `name_student1`, `id_student1`, `name_student2`, `id_student2`, e.g.:\n",
    "\n",
    "```\n",
    "# // BEGIN_TODO [Q0]\n",
    "name_student1 = \"John Smith\"\n",
    "id_student1 = \"1234567\"\n",
    "name_student2 = \"Jane Miller\"\n",
    "id_student2 = \"7654321\"\n",
    "# // END_TODO [Q0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q0]\n",
    "#// END_TODO [Q0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant libraries\n",
    "\n",
    "In this assignment we will be using mainly the following libraries:\n",
    "\n",
    "- `pandas` for organizing the data\n",
    "- `numpy` for operating on the data\n",
    "- `matplotlib` for visualizing the data\n",
    "- `sklearn` for training and evaluating a model on the data\n",
    "- other utility libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "\n",
    "The data resides in two files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_energy = pd.read_csv(\"energy_171819.csv\")\n",
    "raw_energy[95500:956000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_weather = pd.read_csv(\"weather_171819.csv\")\n",
    "raw_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analysing data it is important to understand its semantics. In IoT one needs to be extra careful, especially when integrating data from various sources. The very basic information are the units of the measurements, but also the specifications of the sensors gathering the data and the processes that are being monitored. For example, in this case the specification of the solar panel installation states that it can generate max 153k Jouls per minute.  \n",
    "\n",
    "Assume the following for the energy data:\n",
    "- `seconds` is the time the sample was recorded (UTC) as an epoch timestamp\n",
    "- `total_consumption` is the total amount of electricity that was pulled from the grid (kWh)\n",
    "- `total_production` is the total amount of electricity that was pushed into the grid (kWh)\n",
    "- `solar_production` is the amount of eletricity that was produced since the last sample (Wh).\n",
    "- `total_solar_production` is the total amount of electricity produced by the solar panels (kWh)\n",
    "\n",
    "Assume the following for the weather data:\n",
    "- `time` is the time the sample was recorded (UTC)\n",
    "- `clouds` measures whether it was cloudy at the time when the sample was taken, ranging from 0-3, 0 meaning no clouds and 3 meaning very cloudy.\n",
    "- `temperature` is the still temperature (C).\n",
    "- `wind direction` given in South (Z), West (W), North (N), and (East), or a combination thereof.\n",
    "- `wind speed` in m/s. \n",
    "- `visibility` in meters.\n",
    "- `air pressure` in hPa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "\n",
    "Exploration is usually the first step in any data analysis task. Visualization is an important tool for exploring the data. It gives insights into the structure and semantics of the data and indications for how to clean it.\n",
    "\n",
    "The `matplotlib` library provides a collection of useful plots, such as a line plot, scatter plot, histogram, scatter mattrix, etc. You can find out more about this library at \n",
    "\n",
    "- https://matplotlib.org/users/pyplot_tutorial.html\n",
    "- https://matplotlib.org/devdocs/gallery/\n",
    "\n",
    "The `pandas` library also contains convenient wrappers around the `matplotlib` library for visualizing data frames and series:\n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/stable/visualization.html\n",
    "\n",
    "Let's draw a simple plot of the energy data (note that we're only plotting a small part of the data here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (14, 9) # (w, h)\n",
    "X = raw_energy[:300000][\"seconds\"]\n",
    "Y = raw_energy[:300000][\"total_solar_production\"]\n",
    "plt.plot(X, Y)\n",
    "plt.xlabel('Epoch time (s)')\n",
    "plt.ylabel('Total solar production (kWh)')\n",
    "plt.axis([X.min(), X.max(), Y.min(), Y.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: explore the values in different columns (experiment with different visualizations, e.g. line, histogram, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Simple visual inspection of the data can already tell you a lot about what you are working with. The energy data covers 2017 , 2018, and 2019, but because the data was split sometime beforehand, some time ranges will be missing.\n",
    "\n",
    "Assign to `question_missing_months` in the form of a list the months that are missing from the energy data (for example, if June and July of 2017 are missing, the list would be `[\"2017-06\", \"2017-07\"]`). \n",
    "\n",
    "Not only are there months missing, each month that is in the energy data has some missing days as well. Assign to `question_num_missing_days` the number of days that is missing from each month.\n",
    "\n",
    "You will have to convert the timestamps in the data to retrieve the months and days. Note that the Netherlands is in timezone UTC+1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q1]\n",
    "#// END_TODO [Q1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data\n",
    "\n",
    "Data cleaning is an important part of any data analysis task. According to the general wisdom, most effort actually is spent on data cleaning. It involves preparing the data for the following steps, e.g. converting values to the right type, filling in missing values, removing outliers, normalizing the data, etc.\n",
    "\n",
    "In the plot above you may have noticed vertical lines (you may have to plot a shorter time range to spot them). These lines correspond to 0 values and are likely to be measurement errors (e.g. the solar panel meter has crashed). Such outliers will often negatively impact the accuracy of the predictive model. However, care must be taken to properly define what constitutes an outlier and what constitutes a valid measurement. Some odd looking measurements may actually contain important evidence for proving or disproving a hypothesis. In this case the 0 values can be considered measurement errors and should be removed.\n",
    "\n",
    "Pandas provides convenient methods for selecting subsets of the data that can be used for removing outliers:\n",
    "\n",
    "- https://jakevdp.github.io/PythonDataScienceHandbook/03.02-data-indexing-and-selection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove the samples with production total of 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data that is collected in the wild will sometimes contain formatting inconsistencies. It is a good habit to check the data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_energy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the `'total_consumption'`, `'total_production'`, `'total_solar_production'` columns are of numerical type, however, the `solar_production` is of an `object` type (which is also used for strings), while looking at the specification of the column above we would expect a numerical type. Modeling this column later will require a numerical column, so it will need to be converted to the right type first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: explore the offending values in the solar_production column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Convert empty strings in the `'solar_production'` column to `np.nan`. Convert the remaining values in the `'solar_production'` column to `float` type, and copy the resulting column to a variable named `solar_production_column`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q2]\n",
    "#// END_TODO [Q2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer features\n",
    "\n",
    "The goal of this assignment is to predict the hourly energy output of the solar panels given the weather forecast. This requires to relate the energy samples with the weather samples, basically attaching the energy production label to the weather measurements. However, the *total* energy and weather samples are taken approximately every 10 seconds and 10 minutes, respectively.\n",
    "\n",
    "####  Aggregate per hour\n",
    "\n",
    "We can use pandas grouping functions to aggregate the samples per hour, taking the largest  measurement in that hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"total_solar_production\"\n",
    "energy = raw_energy.copy()\n",
    "times = pd.to_datetime(energy[\"seconds\"], unit='s')\n",
    "\n",
    "energy = energy.groupby([times.dt.year, times.dt.month, times.dt.dayofyear, times.dt.hour])[[col]].agg(np.max)\n",
    "energy.index.names = [\"year\", \"month\", \"day\", \"hour\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 ###\n",
    "\n",
    "Note that the hourly aggregation using the maximum works well for columns containing the totals. Does it also work for the `'solar_production'` column?\n",
    "\n",
    "1. Yes, but the aggregation method needs to be changed to fit the solar_production data type\n",
    "2. Yes, the same aggregation method can be applied\n",
    "3. No, it's not possible to aggegrate over the solar_production field\n",
    "4. No, aggregating over the solar_production field in any way does not make sense.\n",
    "5. None of the above.\n",
    "\n",
    "Assign an integer corresponding to the correct answer to variable `question_aggregation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q3]\n",
    "#// END_TODO [Q3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After aggregation, some cells can contain `Nan` values (e.g. when trying to compute a maximum for an hour during which no samples were recorded). Therefore, after performing such operations one should decide what to do with any NaN values. In this case we chose to remove such samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = energy.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After grouping, merging and slicing operations, the index of a data frame might need to be recomputed, to reflect the new ordering of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = energy.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the hourly production\n",
    "\n",
    "We are interested in predicting the solar panel output in a given hour. However, the `'total_solar_production'` column in the energy data frame at this point contains the total solar panel output until the end of that hour. Assuming that the data set contains a sample for every hour, i.e. there are no gaps, the hourly output can be compouted by taking the difference between the previous sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy[\"production\"] = energy[col] - energy[col].shift(1)\n",
    "energy = energy.dropna().reset_index()\n",
    "energy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 ###\n",
    "\n",
    "After creating the production column there are NaNs in the data. Where do they come from, and why is the index recomputed?\n",
    "\n",
    "1. The NaN values are caused by missing values in the original data due to sensor errors, and the index is reset because a column has been added.\n",
    "2. The NaN values are caused by missing values in the original data due to the way the column is calculated, and the index is reset because a column has been added.\n",
    "3. The NaN values are caused by missing values in the original data due to sensor errors, and the index is reset because the number of rows has changed.\n",
    "4. The NaN values are caused by missing values in the original data due to the way the column is calculated, and the index is reset because the number of rows has changed.\n",
    "\n",
    "Assign the integer corresponding to the correct answer to the variable `question_production`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q4]\n",
    "#// END_TODO [Q4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform a similar aggregation for the `clouds` column in the weather data. Note that rather than choosing the maximum, we take the average `clouds` value per hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = raw_weather.copy()\n",
    "times = pd.to_datetime(weather[\"time\"])\n",
    "weather = weather.groupby([times.dt.year, times.dt.month, times.dt.dayofyear, times.dt.hour])[\"clouds\"].agg(np.mean)\n",
    "weather.index.names = [\"year\", \"month\", \"day\", \"hour\"]\n",
    "weather = weather.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the data frames\n",
    "\n",
    "Now that both data frames are expressed in terms of hours and the energy data frame contains the hourly solar panel output, we can use pandas to merge them.\n",
    "\n",
    "**Important:** when dealing with times in data from various sources one must be very carefull about the semantics of the time, such as the time-zone or the daylight-saving. Luckily, in this assignment both energy and weather data use UTC time, so no extra preprocessing is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(energy, weather).dropna().reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the engineered features\n",
    "\n",
    "After engineering features it is a good idea to explore the data set again, to see if extra cleaning is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = data[\"production\"].values\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.hist(values, 50);\n",
    "plt.xlabel('Production (kWh)')\n",
    "plt.ylabel('Frequency')\n",
    "print (min(values), max(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The small variance of the values and their large range suggests there are some outliers. This can be also visualized in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, col):\n",
    "    x = df[\"day\"]\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(x, df[col], 'bo', markersize=1)\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel(col)\n",
    "\n",
    "plot(data, \"production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure suggests that there are indeed outliers in the energy production data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "The plot shows some outliers. How do you explain these? Note that there may be more than one correct anwser.\n",
    "\n",
    "1. There is actually an oversight in the previous calculations which causes the outliers.\n",
    "2. There is some unclean data present due to sensor errors.\n",
    "3. There were some very clear and sunny days.\n",
    "4. The outliers represent multiple days of production.\n",
    "\n",
    "Assign the integer(s) corresponding to the correct answer(s) as a list to the variable `question_outliers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q5]\n",
    "#// END_TODO [Q5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when removing the energy samples containing 0 values in `raw_energy` earlier, it was clear how to define an outlier. In this case, however, one must carefully decide how to define an outlier, to avoid introducing bias. You can read more about outlier detection here:\n",
    "\n",
    "- Section 3.3.3 of \"Introduction to Statistical Learning\"\n",
    "- http://scikit-learn.org/stable/modules/outlier_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "How do you best define an outlier for this data set?\n",
    "\n",
    "1. Calculate the average production, and define an outlier based on standard deviations.\n",
    "2. Build a model for the expected production, and label outliers based on the model predictions.\n",
    "3. Set a fixed threshold for outliers based on the characteristics of the solar panels.\n",
    "4. Estimate a fixed threshold for outliers by hand based on the above plot.\n",
    "\n",
    "Assign an integer corresponding to the correct answer to variable `question_outlier_definition`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q6]\n",
    "#// END_TODO [Q6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Remove the outliers from the `data` data frame. Assign the resulting data frame to variable `data_no_outliers`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q7]\n",
    "#// END_TODO [Q7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visualization is often helpful to check if the results of our data processing and analysis meet our expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot the clouds feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been cleaned and converted, let's take another look. Aggregate the months that are present in the training data, and determine which month of the year is on average the most productive in terms of solar production across the 3 years. Assign the integer corresponding to the month to `most_productive_month`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q8]\n",
    "#// END_TODO [Q8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model\n",
    "\n",
    "For training and evaluating the performance of a model we need to split the data into a training and a test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_no_outliers[[\"clouds\"]].values\n",
    "y = data_no_outliers[\"production\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "\n",
    "After a model is trained we would like to estimate how well it is performing, whether we can actually trust its predictions if it were deployed. Model performance can be estimated using various visualisations and statistics (see Section 3.1.3 of [ISLR])\n",
    "\n",
    "#### Model fit\n",
    "\n",
    "If the feature space is 1 or 2 dimensional, then we can easily plot the model to illustrate how well it fits the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(min(X), max(X), 100)\n",
    "X_plot = x_plot.reshape(-1, 1)\n",
    "y_plot = model.predict(X_plot)\n",
    "\n",
    "dots, = plt.plot(X_test, y_test, 'bo', markersize=2, color=\"red\", label=\"training data\");\n",
    "line, = plt.plot(x_plot, y_plot, linewidth=2, label=\"model\");\n",
    "plt.xlabel('Clouds')\n",
    "plt.ylabel('Production (kWh)')\n",
    "plt.legend(handles=[dots, line]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the R2 score to assign a number to how well the model fits the data. It estimates how much of the variance in the data is explained by the model, i.e. how well the model fits the data. A score of 1 means the model captures all of the variance, and a score of 0 means the model does not capture any of the variance.\n",
    "\n",
    "You can read more about the R2 score in Section 3.1.3 of \"Introduction to Statistical Learning\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residuals\n",
    "\n",
    "We can also plot a histogram of the residuals (or errors), i.e. the deviations of the values predicted by our model from the ground truth values (from the test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "plt.title(\"Distribution of the residuals\")\n",
    "plt.hist(y_test - y_pred, 50);\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the histogram you will notice that distribution of the residuals is not symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Does the model tend to over-estimate, or under-estimate the solar panel output?\n",
    "\n",
    "1. The model tends to under-estimate.\n",
    "2. The model tends to over-estimate.\n",
    "3. The model is not biased\n",
    "\n",
    "Assign an integer corresponding to the correct answer to variable `question_bias`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q9]\n",
    "#// END_TODO [Q9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model is not biased, or if we are not interested in the bias, then we can compute the mean absolute deviation (MAD) to estimate the expected error of a prediction. E.g. a MAD = 0.345 means that we expect on average our predition to be off by 0.345kWh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve the model\n",
    "\n",
    "We have shown here a simple linear model mapping the `clouds` feature to the `hourly_production` label. However, this model does not perform very well. The problem could be that the model is underfitting or overfitting the data. You can find more about under- and overfitting in Section 2.1.2, 2.1.3, 6.1 of \"Introduction to Statistical Learning\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10 ###\n",
    "\n",
    "Is the model underfitting or overfitting? What makes you say that? Investigate and then explain in at most 100 words why you think the model is underfitting or overfitting. Assign the explanation to the variable `question_fitting`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q10]\n",
    "#// END_TODO [Q10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could try several things to improve the model.\n",
    "\n",
    "#### Add more features\n",
    "\n",
    "The simple linear model assumed that there is a strong relation ship between the clouds (or their absence) and the output of the solar panels. However, clouds alone are not a sufficient indicator, e.g. during the night. You may plot a histogram showing how the `clouds` values are distributed during the 24 hours of a day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(weather.dropna().hour.values, weather.dropna().clouds.values);\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Clouds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Why is the `clouds` column alone not a good indicator for the solar panel output?\n",
    "\n",
    "Answer this question in max. 100 words and assign your string answer to the variable `question_clouds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q11]\n",
    "#// END_TODO [Q11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the `clouds` column alone may not be sufficient for predicting the solar planel output, it can be used in combination with other features. Therefore, one way of improving the simple linear model could be to extend it with more features. You can gain insight into which features could be relevant by plotting the relationship between the features and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use the scatter matrix graph to explore the relationship between the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12 ###\n",
    "\n",
    "Which features are most promising for predicting the solar panel output? Select the two features that are most strongly correlated with production.\n",
    "\n",
    "- `'year'`\n",
    "- `'month'`\n",
    "- `'day'`\n",
    "- `'hour'`\n",
    "- `'air pressure'`\n",
    "- `'visibility'`\n",
    "- `'wind speed'`\n",
    "- `'temperature'`\n",
    "\n",
    "Assign a list of strings corresponding to the promising features to variable `question_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q12]\n",
    "#// END_TODO [Q12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that using additional features may require aggregating them per hour. The `clouds` feature was aggregated taking the maximum value within a given hour, but this may not be suitable for all features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13 ###\n",
    "\n",
    "Using your new-found knowledge of the features, re-define the data on which you train and evaluate your model. Try to improve your model as much as possible by only changing the selection of features.\n",
    "\n",
    "Assign your new data, new model and the corresponding MAD score to the variables `improved_data`, `improved_model`, `improved_mad`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: improve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q13]\n",
    "#// END_TODO [Q13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a more or less flexible model\n",
    "\n",
    "Another way is to add flexibility to the model e.g. by changing it to a polynomial model or a neural network. You can read more about simple extensions of the linear model in Section 3.3.2 and 6.2 of \"Introduction to Statistical Learning\".\n",
    "\n",
    "Linear regression is far from the only modeling we can do here. Another model we could use is that of a Decision Tree. What is nice about these types of models is that they show the exact sequence of decisions that a model makes in order to arrive at a prediction. You can read more about Decision Trees at [https://scikit-learn.org/stable/modules/tree.html]. Note that in this instance, we will want to use the Decision Tree regression model, not the classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree model has quite a number of parameters, and we encourage you to do so to see their impact on the model's performance. One of the most important ones is that of tree depth. What happens with an increase in depth? Note that there may be more than one correct answer.\n",
    "\n",
    "1. An increase in depth helps to avoid overfitting.\n",
    "2. An increase in depth helps to avoid underfitting.\n",
    "3. An increase in depth makes the model more biased towards new data.\n",
    "4. An increase in depth makes the model less biased towards new data.\n",
    "\n",
    "Assign the integer(s) corresponding to the correct answer(s) as a list to the variable `decision_tree_depth`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q14]\n",
    "#// END_TODO [Q14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Decision Tree model an assign it to the variable `decision_tree`. Inspect it and determine what the three most influential features are according to this model. Assign the names of these features as a list of strings to the variable `decision_tree_features`. You may want to plot the resulting model to help you inspect it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train and inspect decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q15]\n",
    "#// END_TODO [Q15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate the forecasting\n",
    "\n",
    "The `weather_171819_test.csv` file contains the weather data that was held out from `weather_171819.csv` used for training the solar panel output predictor. This data simulates the weather forcasts and is used for evaluating how your model would perform if it was deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test = pd.read_csv('./weather_171819_test.csv')\n",
    "weather_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the predictions for the hourly solar panel output for the given weather forecasts, i.e. populate the `production` column in the following data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = weather_test.copy()\n",
    "times = pd.to_datetime(prediction[\"time\"])\n",
    "prediction['month'] = times.dt.month\n",
    "prediction['day'] = times.dt.dayofyear\n",
    "prediction['hour'] = times.dt.hour\n",
    "prediction = prediction.drop(prediction[prediction['hour'] == 0].index)\n",
    "prediction = prediction[['month', 'day', 'hour']]\n",
    "prediction = prediction.drop_duplicates().reset_index(drop=True)\n",
    "prediction['production'] = np.nan\n",
    "prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** your model will be evaluated on the held out test set. It is therefore safe to train your *final* model on the entire data set that was provided (rather than the X_train, y_train subsets from the train/test split above), to captures all of the information that is available to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16\n",
    "\n",
    "Fill in the `'production'` column in the prediction data frame with your predictions (do not reorder the rows). Assign the values from the `'production`' column as a Python list to the variable `forecast`. You may use any predictive model from the `sklearn` package (please do not use any packages that are not already included in this notebook). You can take a look through the contents of `sklearn` at [https://scikit-learn.org/stable/supervised_learning.html] to find supervised models that suit this purpose, such as Random Forests and Multi-layer Perceptrons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q16]\n",
    "#// END_TODO [Q16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For automating the evaluation of your predictions, call the evaluate function that is defined in the `evaluate.py` script (do not edit the code lines below!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from evaluate_stub import *\n",
    "evaluate(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, make sure that the `prediction` data frame contains a `production` column and 1919 rows.\n",
    "\n",
    "Your solution will be evaluated based on the mean absolute error metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reliability\n",
    "\n",
    "We often assume that the trained model will operate on data from the same distribution as the data it was trained on (see Chapter 1 of the book \"Dataset Shift in Machine Learning\"). However, sometimes these assumptions are not true.\n",
    "\n",
    "Using the model you trained for question 13, evaluate the model's performance on the data set provided below. It contains the energy and weather data for part of the year 2020. Note that as before, this is raw data. You will need to do some cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_energy_20 = pd.read_csv('./energy_20.csv')\n",
    "raw_weather_20 = pd.read_csv('./weather_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the model from previous question on the new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 17\n",
    "\n",
    "Investigate and then explain in at most 100 words in the variable `question_change` what you think may be responsible for the change in your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Investigate changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q17]\n",
    "#// END_TODO [Q17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 18\n",
    "\n",
    "To make your model robust to these kind of changes, you may want to re-train it on more appropriate data. Using all the data you have been provided so far, compose more suitable training and validation data sets, and assign them to `new_training_data` and `new_validation_data`, respectively. the Scikit-Learn library has some potentially useful functions for generating these data sets (https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q18]\n",
    "#// END_TODO [Q18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides solar production, we are also interested in predicting energy consumption. Being able to accurately predict the power bill may save us from any surprises in the future. The year 2020 has been rather different from most other years, to say the least. Now that you have the data for part of the year 2020, let's look into energy consumption anomalies that may be found here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The energy consumption shows two dips in the data from 2020 due to the turning off of large electrical appliances. For each of the dips, fill in the start and end day when the decrease occurred in the variables `consumption_dip_1` and `consumption_dip_2` as a list of two dates each. Please use the YYYY-MM-DD format (e.g. `[\"2020-02-12\", \"2020-02-14\"]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q19]\n",
    "#// END_TODO [Q19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 20\n",
    "\n",
    "Consumption may depend on other factors than production, so we may need to reconsider the features we chose in question 12. Considering the new training target, which two features from question 12 are most promising for the prediction of energy consumption? Assign them to `question_consumption_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q20]\n",
    "#// END_TODO [Q20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate your new model on the data from 2017 through 2019 (do not include the data from 2020) so you can predict the energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a new model to predict energy consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 21\n",
    "\n",
    "As in question 17, check this new model's performance when predicting the energy consumption for the data from 2020. Is there a shift taking place in the data underlying the model? If so, what kind of shift do you think it is? Assign the integer corresponding to the correct answer to `question_consumption_shift`.\n",
    "\n",
    "1. Sample covariate shift\n",
    "2. Source component shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Q21]\n",
    "#// END_TODO [Q21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback\n",
    "\n",
    "Please fill in this questionaire to help us improve this course for the next year. Your feedback will be anonymized and will not affect your grade in any way!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many hours did you spend on these Exercises?\n",
    "\n",
    "Assign a number to `feedback_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Feedback_1]\n",
    "#// END_TODO [Feedback_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How difficult did you find these Exercises?\n",
    "\n",
    "Assign an integer to `feedback_difficulty`, on a scale 1 - 10, with 1 being very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Feedback_2]\n",
    "#// END_TODO [Feedback_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did you take the course Foundations of Data Mining?\n",
    "\n",
    "Assign a boolean value to `feedback_foundations` (True or False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Feedback_3]\n",
    "#// END_TODO [Feedback_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did you do any other Machine Learning-related coursework (university/workshop/online/etc)\n",
    "\n",
    "Assign an answer to `feedback_other`, describing any other coursework done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Feedback_4]\n",
    "#// END_TODO [Feedback_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Which parts of the assignment did you like?\n",
    "\n",
    "Assign a string to `feedback_like`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Feedback_5]\n",
    "#// END_TODO [Feedback_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Which parts of the assignment could be improved?\n",
    "\n",
    "Assign a string to `feedback_improve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [Feedback_6]\n",
    "#// END_TODO [Feedback_6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
